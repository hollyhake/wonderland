--- 
title: "Tracking memory decline"
author: "Holly Hake"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---

# Introduction

Placeholder



<!--chapter:end:index.Rmd-->

# Methods

## Rate of Forgetting

'Rate of forgetting' is the probability of retrieving a particular memory over time and is rooted in a Bayesian model of cognition.

## Participants 

A total of (#) English-speaking participants aged between (#) and (#) years old were recruited on a rolling basis from the Alzheimer's Disease Research Center (ADRC). Participants were enrolled for one year to get a comprehensive view of how their memory changes over time. All participants provided informed consent and were compensated with $100 for their participation in the online memory game portion of the study. All of the recruitment and testing procedures were approved by the University of Washington’s Institutional Review Board.


## Memory Task

Rate of forgetting was estimated using SlimStampen, an adaptive fact learning system (AFLS) described in Sense et al. (2016).


## Data Processing

The repetition, activation, and alpha values for each fact were calculated using two functions from the SlimStampeRData package. The average alpha values for each fact were identified by using the terminal alpha value of each fact (the estimate of alpha at the very last repetition of that fact). The data was then filtered to only contain the first full session (>6 min). This was needed to eliminate any superfluous sessions (some participant's like to complete the task more than once).  




<!--chapter:end:methods.Rmd-->

# Results

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(broom)
library(reshape2)
library(glmnet)
library(readr)

## Graphics
library(ggplot2)
library(ggthemes)
library(ggrepel)
library(ppcor)
library(ggExtra)
library(ggsci)
library(viridis)
library(scales)
library(patchwork)# Multi-plot alignment
library(ggcorrplot)
library(gapminder) # dataset used to make the box plot connected by lines
library(RColorBrewer) 
library(plotly) # Added to make interactive graphs 
library(lubridate) # Added to make interactive graphs; use different date funcs
library(stringr) # Added to make interactive graphs; use different txt funcs
library(extrafont) # Added to make interactive graphs; change font on graphs
library(htmlwidgets) # Added to make interactive graphs; make exports interactive
library(cowplot)

## Tables
library(kableExtra)
library(xtable)

# Date functions
library(anytime)
library(lubridate)

# SlimStampen

#install.packages("devtools") # Install SlimStampen packages. Instructions on https://github.com/VanRijnLab/SlimStampeRData
library(devtools)
#devtools::install_github("VanRijnLab/SlimStampeRData",
                      #   build_vignettes = TRUE,
                       #  dependencies = TRUE,
                        # force = TRUE) 
# The console will show a prompt asking whether all packages should be updated. Select option 1 (by typing 1 and then pressing enter), this will update all packages.
vignette("SlimStampeRVignette")
library(SlimStampeRData)

```


```{r, echo=FALSE, results= 'hide'}

# Load data
load("C:/Users/17203/Documents/GitHub/Blaarkop/data/SlimStampen_2022-08-22.RData")

# Filter for just ADRC subjects & group by clinical status
groups <- read_csv("C:/Users/17203/Documents/GitHub/Blaarkop/groups.csv", show_col_types = FALSE)
data %>% 
  filter(userId %in% groups$userId) -> data

```


```{r, echo=FALSE, results= 'hide'}

# Calculate fact rep, activation, and alpha 
MAX_ALPHA=0.8
data <- data %>%
  calculate_repetition() %>%
  calculate_alpha_and_activation(maxAlpha=MAX_ALPHA)

```
```{r, echo=FALSE, results= 'hide'}


options(dplyr.summarise.inform = FALSE) # Disable the "`summarise()` has grouped output by" message 

# Calculate avg alpha
data_lastRep <- data %>%
  group_by(lessonId, userId, sessionId, factId) %>%
  mutate(LastRepetition = max(repetition)) %>%
  filter(repetition == LastRepetition) %>%
  ungroup()

data_avg1 <- data_lastRep %>%
  group_by(userId, lessonTitle, lessonId, sessionId) %>%
  summarise(MeanAlpha = mean(alpha), MedianAlpha = median(alpha)) 

data_avg2 <- data %>%
  group_by(lessonId, userId, sessionId) %>%
  summarise(correct = mean(correct), responseTime=mean(reactionTime)) %>%
  ungroup()

data_avg <- data_avg1 %>% inner_join(data_avg2)

data_avg %>% 
  group_by(userId, lessonTitle, lessonId) %>% 
  summarize(numSess=length(unique(sessionId))) 


# Filter the sessions
sessionData <- data %>% 
  group_by(userId, sessionId, lessonId, lessonTitle) %>% 
  summarize(duration = (max(presentationStartTime) - min(presentationStartTime))/60000,
            start = min(presentationStartTime),
            legit = if_else(duration > 6, T, F)) 

sessionData <- sessionData %>% 
  group_by(userId, lessonId, lessonTitle) %>% 
  arrange(start, by_group=T) %>%
  mutate(sessionRank = seq(1, length(start)))

sessionDataFiltered <- sessionData %>%
  filter(legit == T) %>%
  group_by(userId, lessonId) %>%
  mutate(minRank = min(sessionRank))

sessionData <- sessionData %>%
  inner_join(sessionDataFiltered) %>%
  mutate(usable = if_else(minRank == sessionRank, T, F))


# Group by clinical status
clinical <- inner_join(data_avg, groups) %>%
  inner_join(sessionData) %>%
  filter(usable == T)


```


```{r, echo=FALSE}
clinical$userId <- as.character(clinical$userId)
clinical <- clinical %>%
  mutate(paired= factor(userId))

# Change responseTime from ms to s
clinical$responseTime <- (clinical$responseTime/1000)

# Delete practice
clinical <- clinical[!(clinical$lessonTitle=="01 Practice"), ]

# **Testing taking out outlier participant lessons
#clinical <- clinical[-c(67,70,72,73,87), ] 
#clinical <- clinical[!(clinical$userId=="69415"), ]


# Order the lessons by week
clinical$level_order<- factor(clinical$lessonTitle, level = c('Pasta','Swahili 1','Flowers','European Capitals 1','Birds', 'Newspapers','Asian Flags', 'Folktales', 'Maps', 'US Towns 1'))

xlabels <- c("Pasta", "Swahili", "Flowers", "Capitals", "Birds","News", "Flags", "Folktales", "Maps", "Towns")

clinical %>% 
  group_by(level_order, clinicalStatus) %>% 
  summarise(n=length(userId)) %>%
  pivot_wider(names_from=clinicalStatus, values_from = n) %>%
  rowwise() %>% 
  mutate(sumVar = sum(c_across(Control:MCI))) %>%
  kbl(caption= "Number of Control and MCI participants that completed each lesson", col.names = c("Lesson", "Control", "MCI", "Total")) %>%
  kable_styling() %>%
  column_spec(3,color = "purple") %>%
  column_spec(4,bold= T,border_left = T) %>%
  column_spec(1, image = spec_image(c(
    "C:/Users/17203/Documents/wonderland/images/pasta.png",
    "C:/Users/17203/Documents/wonderland/images/swahili.png", 
    "C:/Users/17203/Documents/wonderland/images/flowers.png", 
    "C:/Users/17203/Documents/wonderland/images/eurocaps.png", 
    "C:/Users/17203/Documents/wonderland/images/birds.png",
    "C:/Users/17203/Documents/wonderland/images/news.png",
    "C:/Users/17203/Documents/wonderland/images/asianflags.png",
    "C:/Users/17203/Documents/wonderland/images/folktales.png",
    "C:/Users/17203/Documents/wonderland/images/maps.png",
    "C:/Users/17203/Documents/wonderland/images/ustowns1.png"
    ), 50, 50)) %>% # Add images to the table 
  kable_paper(full_width = T) 





```
```{r Completion, echo=FALSE, fig.cap="Weekly lessons each participant completed"}

# Order the users by time they joined the study
clinical$user_order<- factor(clinical$userId, level = c('69410','69411','69412','69414','69415','69417','69418','69419','69427','70930','69421','69422','69423','69425','70925'))


#graph.clinical=
  ggplot(clinical, aes(x=level_order, y=user_order, text=paste0(userId))) +
  #geom_boxplot(size=0.1) +
 # geom_line(aes(group=userId, col=userId), size=0.1, position=position_dodge(0)) +
    geom_line(aes(group=userId), size=0.1, position=position_dodge(0)) +
  geom_point(aes(group=paired), color ="green3", size=3, shape=15, stroke=0, position=position_dodge(0)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("participant") +
  ggtitle("Weekly Game Completion") +
  labs(fill="Participant", col="Participant") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        legend.position = "none")

#ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
 # layout(legend = list(orientation = "h")) %>% 
 # config(displayModeBar=FALSE)

```



## Accuracy 

```{r, Acc, echo=FALSE, fig.cap="Accuracy Across Lessons"}

PAcc1=ggplot(clinical, aes(x=level_order, y=correct, col=lessonTitle, fill=lessonTitle)) +
  #geom_violin(width=1, alpha=0.2) +
  geom_boxplot(width=.5, alpha=0.2) +
  #stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape= 1, color="black") +
  geom_point(size=2, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("accuracy") +
  ggtitle("Accuracy Across Lessons") +
  theme_pander() +
  theme(legend.position = "none",
        axis.title.x=element_blank())

PAcc2=ggplot(clinical, aes(y = correct, x = level_order, col = clinicalStatus, fill = clinicalStatus)) +
  #geom_violin(alpha=0.2) +
  geom_boxplot(alpha=0.25) +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  geom_point(size=2, position=position_jitter(0.1)) +
  #stat_summary(geom="ribbon", fun.dat="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  #stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("accuracy") +
  ggtitle(" ") +
 # ggtitle("Accuracy Across Lessons By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 



plot_grid(PAcc1, PAcc2, ncol = 1, nrow = 2)

```


Accuracy (fig \@ref(fig:Acc)) scores were averaged for each participant in each lesson they completed. 

```{r, Accp, echo=FALSE, fig.cap="Accuracy by Participant"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=correct, text=paste0(userId))) +
  geom_boxplot(size=0.1) +
  geom_line(aes(group=userId, col=userId), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=userId, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean accuracy") +
  ggtitle("Accuracy by Participant") +
  labs(fill="Participant", col="Participant") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```

This graph is interactive (fig \@ref(fig:Accp)). Hover over the data points to get a better look at the accuracy scores for each participant. Double click on a participant ID to isolate that participant's data points. 



```{r, AccC, echo=FALSE, fig.cap="Accuracy by Clinical Status"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=correct, col=clinicalStatus, fill=clinicalStatus, text=paste0(userId)))+
  geom_boxplot(size =0.1, alpha=0.2) +
  geom_line(aes(group=paired), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=clinicalStatus, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  scale_color_manual(values = c("gold3", "purple3")) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean accuracy") +
  ggtitle("Accuracy by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```

This graph separates the participants by clinical status (fig \@ref(fig:AccC)). Participants with MCI tend to have less accuracy compared to the controls.  

## Response Time

```{r, RT, echo=FALSE, fig.cap="Response Time Across Lessons"}

PRT1=ggplot(clinical, aes(x=level_order, y=responseTime, col=lessonTitle, fill=lessonTitle)) +
  #geom_violin(width=1, alpha=0.2) +
  geom_boxplot(width=.5, alpha=0.2) +
  #stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape= 1, color="black") +
  geom_point(size=2, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("sec") +
  ggtitle("Response Time Across Lessons") +
  theme_pander() +
  theme(legend.position = "none",
        axis.title.x=element_blank())

PRT2=ggplot(clinical, aes(y=responseTime, x=level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_violin(alpha=0.2) +
  geom_boxplot(alpha=0.25) +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  geom_point(size=2, position=position_jitter(0.1)) +
  #stat_summary(geom="ribbon", fun.dat="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  #stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("sec") +
  ggtitle(" ") +
 # ggtitle("Response Time Across Lessons by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 



plot_grid(PRT1, PRT2, ncol = 1, nrow = 2)

```

Response times (fig \@ref(fig:RT)) were averaged for each participant in each lesson they completed. 


```{r, RTp, echo=FALSE, fig.cap="Response Time by Participant"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=responseTime, text=paste0(userId))) +
  geom_boxplot(size=0.1) +
  geom_line(aes(group=userId, col=userId), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=userId, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("sec") +
  ggtitle("Response Time by Participant") +
  labs(fill="Participant", col="Participant") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```
The graph is interactive (fig \@ref(fig:RTp)). Hover over the data points to get a better look at the response times for each participant. Double click on a participant ID to isolate that participant's data points. 

```{r, RTc, echo=FALSE, fig.cap="Response Time by Clinical Status"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=responseTime, col=clinicalStatus, fill=clinicalStatus, text=paste0(userId)))+
  geom_boxplot(size =0.1, alpha=0.2) +
  geom_line(aes(group=paired), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=clinicalStatus, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  scale_color_manual(values = c("gold3", "purple3")) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("sec") +
  ggtitle("Response Time by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```


## Rate of Forgetting 

The mean Rate of Forgetting for each participant across all lessons. 

```{r, RoF, echo=FALSE, fig.cap="Rate of Forgetting Across Lessons"}

ggplot(clinical, aes(x=level_order, y=MeanAlpha, col=lessonTitle, fill=lessonTitle)) +
  geom_violin(width=1, size=0.1, alpha=0.2) +
  #geom_boxplot(width=.4,size=0.1, alpha=0.2) +
  stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape=1, color="black") +
  geom_point(size=3, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean alpha") +
  ggtitle("Rate of Forgetting Across Lessons") +
  theme_pander() +
  theme(legend.position="none")


```
```{r, RoF1, echo=FALSE, fig.cap="Rate of Forgetting Across Lessons"}

PRoF1=ggplot(clinical, aes(x=level_order, y=MeanAlpha, col=lessonTitle, fill=lessonTitle)) +
  #geom_violin(width=1, alpha=0.2) +
  geom_boxplot(width=.5, alpha=0.2) +
  #stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape= 1, color="black") +
  geom_point(size=2, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("alpha") +
  ggtitle("Rate of Forgetting Across Lessons") +
  theme_pander() +
  theme(legend.position = "none",
        axis.title.x=element_blank())

PRoF2=ggplot(clinical, aes(y=MeanAlpha, x=level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_violin(alpha=0.2) +
  geom_boxplot(alpha=0.25) +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  geom_point(size=2, position=position_jitter(0.1)) +
  #stat_summary(geom="ribbon", fun.dat="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  #stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("alpha") +
  ggtitle(" ") +
 # ggtitle("Rate of Forgetting Across Lessons by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 



plot_grid(PRoF1, PRoF2, ncol = 1, nrow = 2)

```
Rates of Forgetting 'alpha' (fig \@ref(fig:RoF1)) were averaged for each participant in each lesson they completed. 


```{r, RoFp, echo=FALSE, fig.cap="Rate of Forgetting by Participant"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=MeanAlpha, text=paste0(userId))) +
  geom_boxplot(size=0.1) +
  geom_line(aes(group=userId, col=userId), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=userId, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean alpha") +
  ggtitle("Rate of Forgetting by Participant") +
  labs(fill="Participant", col="Participant") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```

```{r, RoFC, echo=FALSE, fig.cap="Rate of Forgetting by Clinical Status"}

# Rate of Forgetting by Clinical Status
graph.clinical=ggplot(clinical, aes(x=level_order, y=MeanAlpha,col=clinicalStatus, fill=clinicalStatus,text=paste0(userId))) +
  geom_boxplot(size=0.1, alpha=0.2) +
  geom_line(aes(group=paired), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=clinicalStatus, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  scale_color_manual(values = c("gold3", "purple3")) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean alpha") +
  ggtitle("Rate of Forgetting by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```
Individuals with MCI tend to have a higher Rate of Forgetting than the age-matched controls (fig \@ref(fig:RoFC)).

```{r, mmRoF, echo=FALSE, fig.cap="Mean and Median Rate of Forgetting by Clinical Status"}

PRoFmean=ggplot(clinical, aes(y=MeanAlpha, x =level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_boxplot() +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="point", fun.data="mean_sdl", size=3) +
  stat_summary(geom="ribbon", fun.dat ="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean alpha") +
  ggtitle("Rate of Forgetting By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "none",
        axis.title.x = element_blank()) 

PRoFmed=ggplot(clinical, aes(y=MedianAlpha, x =level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_boxplot() +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="point", fun.data="mean_sdl", size=3) +
  stat_summary(geom="ribbon", fun.dat ="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("median alpha") +
  #ggtitle("Rate of Forgetting By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 


plot_grid(PRoFmean, PRoFmed, ncol = 1, nrow = 2)
  
```

```{r, RoFANOVA,echo=FALSE}
RoFANOVA <- aov(MeanAlpha ~ (lessonTitle * clinicalStatus) + Error(userId/lessonTitle),
          clinical) 

RoFANOVA %>%
  tidy() %>%
  xtable() %>%
  kbl(caption= "ANOVA using mean ROF as dependent variable and Clinical Status and Lesson as factors", digits = 4) %>%
  kable_paper(full_width = F) 

```

The median Rate of Forgetting for each participant across all lessons.


```{r, RoFANOVAmed,echo=FALSE}
RoFANOVAmed <- aov(MedianAlpha ~ (lessonTitle * clinicalStatus) + Error(userId/lessonTitle),
          clinical) 

RoFANOVAmed %>%
  tidy() %>%
  xtable() %>%
  kbl(caption= "ANOVA using median ROF as dependent variable and Clinical Status and Lesson as factors", digits = 4) %>%
  kable_paper(full_width = F) 
```

## Distribution of Rate of Forgetting

```{r, DisRoF, echo=FALSE, fig.cap="Distribution of Rate of Forgetting by Clinical Status"}

clinical_avg <- clinical %>% 
  group_by(userId, clinicalStatus) %>%
  summarise(RoF = mean(MeanAlpha))

PRoFD1 <- ggplot(clinical, aes(x=MeanAlpha, fill=clinicalStatus)) +
  geom_density(alpha=0.25, col="white", bw=0.02) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Mean Rate of Forgetting") +
  ggtitle("RoF Distributions\n(single sessions)") +
  ylab("Number of Observations") +
  xlim(c(0.2, 0.6)) +
  labs(fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom") 


PRoFD2 <- ggplot(clinical_avg, aes(x=RoF, fill=clinicalStatus)) +
  geom_density(alpha=0.25, col="white", bw=0.03) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Mean Rate of Forgetting") +
  ggtitle("RoF Distributions\n(averaged)") +
  ylab("Number of Observations") +
  xlim(c(0.2, 0.6)) +
  labs(fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom") 


## This is a function from the 'cowplot' package
plot_grid(PRoFD1, PRoFD2, labels=c("A", "B"), ncol = 2, nrow = 1)

```

This figure examines the distribution of ROF values for MCIs and controls, either across all sessions (A) or averaged across all sessions (B) (fig \@ref(fig:DisRoF)). The biggest point of difference, whether single session or averaged sessions, is at an alpha of about #. The double bump in Figure \ref{fig:DisRoF}A is likely due to differences in task difficulty. An interesting point here is that there are some things that are easier for the the MCI than for the controls (shown by that middle section overlap) and this makes it harder for the classifier. If we could build a classifier that has a general idea of difficulty (for instance, have the threshold for “birds”-which is an easier task- be 0.35 instead of 0.37), it would be much better.  

## Classification accuracy

One of the most interesting questions which is, “How diagnostic is the Rate of Forgetting?”  To analyze a parameter's classification accuracy, you can plot an ROC curve. This curve will assess the sensitivity and specificity- two components that measure the inherent validity of a diagnostic test- of ROF as a diagnostic tool. First, we examined the ROC curve for just a single 8 minute session of data.    

```{r, results= 'hide', echo=FALSE}

# Single Session

curve <- NULL
mlclinical <- clinical %>%
  #group_by(userId,clinicalStatus) %>%
  #summarize(MeanAlpha=mean(MeanAlpha), MedianAlpha = median(MeanAlpha)) %>%
  mutate(observed = ifelse(clinicalStatus == "MCI", -1, 1)) 

for (threshold in seq(0.2, 0.8, 0.01)) {
  subthreshold <- mlclinical %>%
    mutate(prediction = ifelse(MeanAlpha <= threshold, 1, -1)) %>%
    mutate(accuracy = ifelse(prediction == observed, 1, 0)) %>%
    group_by(observed) %>%
    summarise(accuracy = mean(accuracy))
  
  tnr <- subthreshold %>% 
    filter(observed == -1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  tpr <- subthreshold %>% 
    filter(observed == 1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  partial <- tibble(Threshold = threshold,
                    TNR = tnr,
                    TPR = tpr)
  if (is.null(curve)) {
    curve <- partial
  } else {
    curve <- rbind(curve, partial)
  }
}

AUC <- 0
step <- 0.01
for (tnr in seq(0, 1, step)) {
  y <- curve %>% filter (TNR <= tnr) %>% filter(TNR == max(TNR)) %>% summarise(TPR = mean(TPR)) %>% as.numeric()
  AUC <- AUC + (y * step)
}

```

```{r, Class, echo=FALSE, fig.cap="Classification Accuracy for different RoF thresholds"}
curve <- curve %>% mutate(auc = (TPR + TNR)/2)

ggplot(arrange(curve, TPR), aes(x=TNR, y=TPR)) + 
  geom_point(size=2, col="purple", alpha=0.5) + 
  geom_line(col="purple") + 
  geom_text_repel(aes(label=paste("RoF =", Threshold, "\n AUC =", percent(auc, .2))), 
                  col="black",
                  #position=position_stack(vjust=0.5), 
                  direction="both",
                  size=3) +
  ylab("Sensitivity (True Positive Rate)") +
  xlab("Specificity (True Negative Rate)") +
  scale_x_reverse() +
  ylim(0, 1) +
  xlim(1, 0) +
  coord_equal() +
  ggtitle("ROC Curve for Different Thresholds (Single)") +
  geom_abline(slope=1, intercept = 1, col="grey", linetype = "dashed") +
  theme_pander()
```

This figure visualizes the ROC curve to see the classification accuracy at each RoF threshold (fig \@ref(fig:Class)). In this case, having a RoF value of 0.# as the diagnostic threshold- that is people with an RoF of 0.# and up are considered mildly cognitively impaired and people with an RoF less than are healthy controls- gives us a diagnostic classification accuracy of #%. All together though, the global AUC for single session is `r AUC`.  

```{r, results='hide', echo=FALSE}

# Average of all sessions

curve <- NULL
mlclinical <- clinical %>%
  group_by(userId,clinicalStatus) %>%
  summarize(MeanAlpha=mean(MeanAlpha), MedianAlpha = median(MeanAlpha)) %>%
  mutate(observed = ifelse(clinicalStatus == "MCI", -1, 1)) 

for (threshold in seq(0.2, 0.8, 0.01)) {
  subthreshold <- mlclinical %>%
    mutate(prediction = ifelse(MeanAlpha <= threshold, 1, -1)) %>%
    mutate(accuracy = ifelse(prediction == observed, 1, 0)) %>%
    group_by(observed) %>%
    summarise(accuracy = mean(accuracy))
  
  tnr <- subthreshold %>% 
    filter(observed == -1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  tpr <- subthreshold %>% 
    filter(observed == 1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  partial <- tibble(Threshold = threshold,
                    TNR = tnr,
                    TPR = tpr)
  if (is.null(curve)) {
    curve <- partial
  } else {
    curve <- rbind(curve, partial)
  }
}

AVGAUC <- 0
step <- 0.01
for (tnr in seq(0, 1, step)) {
  y <- curve %>% filter (TNR <= tnr) %>% filter(TNR == max(TNR)) %>% summarise(TPR = mean(TPR)) %>% as.numeric()
  AVGAUC <- AVGAUC + (y * step)
}
```


```{r, Classavg, echo=FALSE, fig.cap="Classification Accuracy for different averaged RoF thresholds"}
curve <- curve %>% mutate(auc = (TPR + TNR)/2)

ggplot(arrange(curve, TPR), aes(x=TNR, y=TPR)) + 
  geom_point(size=2, col="purple", alpha=0.5) + 
  geom_line(col="purple") + 
  geom_text_repel(aes(label=paste("RoF =", Threshold, "\n AUC =", percent(auc, .2))), 
                  col="black",
                  #position=position_stack(vjust=0.5), 
                  direction="both",
                  size=3) +
  ylab("Sensitivity (True Positive Rate)") +
  xlab("Specificity (True Negative Rate)") +
  scale_x_reverse() +
  ylim(0, 1) +
  xlim(1, 0) +
  coord_equal() +
  ggtitle("ROC Curve for Different Thresholds (AVG)") +
  geom_abline(slope=1, intercept = 1, col="grey", linetype = "dashed") +
  theme_pander()
```

This figure visualizes the ROC curve to see the classification accuracy at each RoF threshold (fig \@ref(fig:Classavg)). The global AUC for averaged sessions is `r AVGAUC`.


## RoF Correlations 

```{r, results ='hide', echo=FALSE}

# create a matrix of Participant by Lesson RoFs:

clinical %>% 
  pivot_wider(id_cols = lessonId, 
              names_from = userId, 
              values_from = MeanAlpha, 
              names_prefix="sub") %>% 
  ungroup() %>% 
  select(-lessonId) %>% 
  as.matrix() %>% 
  t() %>%
  cor(use="complete.obs") -> C

# remove self-correlations
C_noself <- C
C_noself[C==1] <- NA

```

```{r Corr, echo=FALSE, fig.cap="RoF Test-Retest Reliability"}
clinical %>% 
#  filter(!userId %in% tooFew[[1]]) %>% 
  pivot_wider(id_cols = lessonTitle, 
              names_from = userId, 
              values_from = MeanAlpha, 
              names_prefix="sub") %>% 
  ungroup() %>% 
  select(lessonTitle) %>% 
  as.vector() %>% 
  c() -> L

L <- L[[1]]

D <- as.data.frame(C)
names(D) <- L
D$Lesson <- L

D <- as_tibble(D)


correlations <- D %>%
  pivot_longer(cols=-Lesson, names_to = "With", values_to = "r")

correlations$Lesson<- factor(correlations$Lesson, level = c('Pasta','Swahili 1','Flowers','European Capitals 1','Birds', 'Newspapers','Asian Flags', 'Folktales','Maps', 'US Towns 1'))
correlations$With<- factor(correlations$With, level = c('Pasta','Swahili 1','Flowers','European Capitals 1','Birds', 'Newspapers','Asian Flags', 'Folktales','Maps', 'US Towns 1'))

ggplot(correlations, aes(x=Lesson, y=With, fill=r)) +
  geom_tile(col="white", size=1) +
  scale_fill_viridis(option="inferno", limits=c(0, 1)) +
#  scale_fill_continuous(limits=c(0, 1)) +
  coord_equal() +
  ggtitle("RoF Correlations Across Lessons") +
  geom_text(aes(label=sprintf("%0.2f",
                              round(r, digits = 3))), 
            size=3) +
  theme(axis.text.x=element_text(angle=45, hjust = 1)) +
  theme_pander()
```

This figure visualizes the test-retest reliability of the RoF using correlations across materials  (fig \@ref(fig:Corr)). The mean correlation is `r round(mean(C_noself, na.rm=T), 3)`. 

<!--chapter:end:results.Rmd-->


# Supplement

Placeholder


## Lesson Fact Response Times
### Response Time for each fact (interactive)
## Lesson Facts RoF
### Average Rate of Forgetting for Each Lesson's Facts
## Lesson Participant RoF
### Average Rate of Forgetting for Every Participant in Each Lesson
### Average Rate of Forgetting for Every Participant in Each Lesson (Interactive)
#### By Clinical Status

<!--chapter:end:supplement.Rmd-->

