# Results

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(broom)
library(reshape2)
library(glmnet)
library(readr)

## Graphics
library(ggplot2)
library(ggthemes)
library(ggrepel)
library(ppcor)
library(ggExtra)
library(ggsci)
library(viridis)
library(scales)
library(patchwork)# Multi-plot alignment
library(ggcorrplot)
library(gapminder) # dataset used to make the box plot connected by lines
library(RColorBrewer) 
library(plotly) # Added to make interactive graphs 
library(lubridate) # Added to make interactive graphs; use different date funcs
library(stringr) # Added to make interactive graphs; use different txt funcs
library(extrafont) # Added to make interactive graphs; change font on graphs
library(htmlwidgets) # Added to make interactive graphs; make exports interactive
library(cowplot)

## Tables
library(kableExtra)
library(xtable)

# Date functions
library(anytime)
library(lubridate)

# SlimStampen

#install.packages("devtools") # Install SlimStampen packages. Instructions on https://github.com/VanRijnLab/SlimStampeRData
library(devtools)
#devtools::install_github("VanRijnLab/SlimStampeRData",
                      #   build_vignettes = TRUE,
                       #  dependencies = TRUE,
                        # force = TRUE) 
# The console will show a prompt asking whether all packages should be updated. Select option 1 (by typing 1 and then pressing enter), this will update all packages.
vignette("SlimStampeRVignette")
library(SlimStampeRData)

```


```{r, echo=FALSE, results= 'hide'}

# Load data
load("C:/Users/17203/Documents/GitHub/Blaarkop/data/SlimStampen_2022-08-01.RData")

# Filter for just ADRC subjects & group by clinical status
groups <- read_csv("C:/Users/17203/Documents/GitHub/Blaarkop/groups.csv", show_col_types = FALSE)
data %>% 
  filter(userId %in% groups$userId) -> data

```


```{r, echo=FALSE, results= 'hide'}

# Calculate fact rep, activation, and alpha 
MAX_ALPHA=0.8
data <- data %>%
  calculate_repetition() %>%
  calculate_alpha_and_activation(maxAlpha=MAX_ALPHA)

```
```{r, echo=FALSE, results= 'hide'}
# Calculate avg alpha
data_lastRep <- data %>%
  group_by(lessonId, userId, sessionId, factId) %>%
  mutate(LastRepetition = max(repetition)) %>%
  filter(repetition == LastRepetition) %>%
  ungroup()

data_avg1 <- data_lastRep %>%
  group_by(userId, lessonTitle, lessonId, sessionId) %>%
  summarise(MeanAlpha = mean(alpha), MedianAlpha = median(alpha)) 

data_avg2 <- data %>%
  group_by(lessonId, userId, sessionId) %>%
  summarise(correct = mean(correct), responseTime=mean(reactionTime)) %>%
  ungroup()

data_avg <- data_avg1 %>% inner_join(data_avg2)

data_avg %>% 
  group_by(userId, lessonTitle, lessonId) %>% 
  summarize(numSess=length(unique(sessionId))) 


# Filter the sessions
sessionData <- data %>% 
  group_by(userId, sessionId, lessonId, lessonTitle) %>% 
  summarize(duration = (max(presentationStartTime) - min(presentationStartTime))/60000,
            start = min(presentationStartTime),
            legit = if_else(duration > 6, T, F))

sessionData <- sessionData %>% 
  group_by(userId, lessonId, lessonTitle) %>% 
  arrange(start, by_group=T) %>%
  mutate(sessionRank = seq(1, length(start)))

sessionDataFiltered <- sessionData %>%
  filter(legit == T) %>%
  group_by(userId, lessonId) %>%
  mutate(minRank = min(sessionRank))

sessionData <- sessionData %>%
  inner_join(sessionDataFiltered) %>%
  mutate(usable = if_else(minRank == sessionRank, T, F))

# Order by week 
sessionDataWeek <- sessionData %>% 
  group_by(userId) %>%
  mutate(date = anytime(start/1000)) %>%
  #mutate(weekTime = floor(start/(1000*60*60*24*7))) %>%
  mutate(experimentStart = "2022-06-15 00:00:01") %>%
  mutate(firstDate = anytime(min(start/1000))) %>%
  mutate(relativeWeek = (as_datetime(experimentStart) %--% as_datetime(firstDate))/weeks(period(1))) %>%
  mutate(absoluteWeek = (as_datetime(experimentStart) %--% as_datetime(date))/weeks(period(1))) %>%
  mutate(week = 1 + floor(absoluteWeek) - floor(relativeWeek))

# Group by clinical status
clinical <- inner_join(data_avg, groups) %>%
  inner_join(sessionData) %>%
  filter(usable == T)

```

```{r, echo=FALSE}
clinical$userId <- as.character(clinical$userId)
clinical <- clinical %>%
  mutate(paired= factor(userId))

# Delete practice
clinical <- clinical[!(clinical$lessonTitle=="01 Practice"), ]

# Order the lessons by week
#level_order<- factor(clinical$lessonTitle, level = c('01 Practice','Pasta','Swahili 1','Flowers','European Capitals 1','Birds', 'Newspapers'))
clinical$level_order<- factor(clinical$lessonTitle, level = c('Pasta','Swahili 1','Flowers','European Capitals 1','Birds', 'Newspapers','Asian Flags'))

xlabels <- c("Pasta", "Swahili", "Flowers", "Capitals", "Birds","News", "Flags")

clinical %>% 
  group_by(level_order, clinicalStatus) %>% 
  summarise(n=length(userId)) %>%
  pivot_wider(names_from=clinicalStatus, values_from = n) %>%
  kbl(caption= "Number of Control and MCI participants that completed each lesson", col.names = c("Lesson", "Control", "MCI")) %>%
  kable_paper(full_width = F) 



# Add images to the table 
#%>%
 # column_spec(1, image = spec_image(c("C:/Users/17203/Documents/wonderland/images/flowers.png","C:/Users/17203/Documents/wonderland/images/birds.png", "C:/Users/17203/Documents/wonderland/images/birds.png", "C:/Users/17203/Documents/wonderland/images/birds.png", "C:/Users/17203/Documents/wonderland/images/birds.png","C:/Users/17203/Documents/wonderland/images/birds.png","C:/Users/17203/Documents/wonderland/images/birds.png"), 50, 50))
```

## Accuracy and Response Time

```{r, Acc, echo=FALSE, fig.cap="Accuracy and Response Time Across Lessons"}

PAcc1=ggplot(clinical, aes(x=level_order, y=correct, col=lessonTitle, fill=lessonTitle)) +
  geom_violin(width=1, alpha=0.2) +
  geom_boxplot(width=.5, alpha=0.2) +
  #stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape= 1, color="black") +
  geom_point(size=3, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Accuracy") +
  ggtitle("Accuracy Across Lessons") +
  theme_pander() +
  theme(legend.position = "none",
        axis.title.x=element_blank())

PRT1=ggplot(clinical, aes(x=level_order, y=responseTime, col=lessonTitle, fill=lessonTitle)) +
  geom_violin(width=1, alpha=0.2) +
  geom_boxplot(width=.5, alpha=0.2) +
  #stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape= 1, color="black") +
  geom_point(size=3, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Response Time (ms)") +
  ggtitle("Response Time Across Lessons") +
  theme_pander() +
  theme(legend.position = "none",
        axis.title.x=element_blank())


plot_grid(PAcc1, PRT1, ncol = 1, nrow = 2)

```

Both the accuracy and response times were averaged for each participant in each lesson they completed (fig \@ref(fig:Acc)). 

```{r, Accp, echo=FALSE, fig.cap="Accuracy by Participant"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=correct, text=paste0(userId))) +
  geom_boxplot(size=0.3) +
  geom_line(aes(group=paired), size=0.2, position=position_dodge(0))+
  geom_point(aes(fill=userId, group=paired), size=3, shape=20, stroke=0, position=position_dodge(0))+
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Mean Accuracy") +
  ggtitle("Accuracy by Participant") +
  labs(fill="Participant") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```

This graph is interactive (fig \@ref(fig:Accp)). Hover over the data points to get a better look at the accuracy scores for each participant. Double click on a participant ID to isolate that participant's data points. 

```{r, AccC, echo=FALSE, fig.cap="Accuracy by Clinical Status"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=correct, col=clinicalStatus, fill=clinicalStatus, text=paste0(userId)))+
  geom_boxplot(size =0.3, alpha=0.1) +
  geom_line(aes(group=paired), size=0.2, position=position_dodge(0)) +
  geom_point(aes(fill=clinicalStatus, group=paired), size=3, shape=20, stroke=0, position=position_dodge(0)) +
  scale_color_manual(values = c("gold3", "purple3")) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Mean Accuracy") +
  ggtitle("Accuracy by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```

This graph separates the participants by clinical status (fig \@ref(fig:AccC)). Participants with MCI tend to have less accuracy compared to the controls.  

```{r, RTp, echo=FALSE, fig.cap="Response Time by Participant"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=responseTime, text=paste0(userId))) +
  geom_boxplot(size=0.3) +
  geom_line(aes(group=paired), size=0.2, position=position_dodge(0))+
  geom_point(aes(fill=userId, group=paired), size=3, shape=20, stroke=0, position=position_dodge(0))+
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Mean Response Time (ms)") +
  ggtitle("Response Time by Participant") +
  labs(fill="Participant") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```
The graph is interactive (fig \@ref(fig:RTp)). Hover over the data points to get a better look at the response times for each participant. Double click on a participant ID to isolate that participant's data points. 

```{r, RTc, echo=FALSE, fig.cap="Response Time by Clinical Status"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=responseTime, col=clinicalStatus, fill=clinicalStatus, text=paste0(userId)))+
  geom_boxplot(size =0.3, alpha=0.1) +
  geom_line(aes(group=paired), size=0.2, position=position_dodge(0)) +
  geom_point(aes(fill=clinicalStatus, group=paired), size=3, shape=20, stroke=0, position=position_dodge(0)) +
  scale_color_manual(values = c("gold3", "purple3")) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Mean Response Time (ms)") +
  ggtitle("Response Time by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```


## Rate of Forgetting 

### Mean Rate of Forgetting 

The mean Rate of Forgetting for each participant across all lessons. 

```{r, RoF, echo=FALSE, fig.cap="Rate of Forgetting Across Lessons"}

ggplot(clinical, aes(x=level_order, y=MeanAlpha, col=lessonTitle, fill=lessonTitle)) +
  geom_violin(width=2, alpha=0.2) +
  geom_boxplot(width=.5, alpha=0.2) +
  stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape=1, color="black") +
  geom_point(size=3, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Mean Rate of Forgetting") +
  ggtitle("Rate of Forgetting Across Lessons") +
  theme_pander() +
  theme(legend.position="none")


```

```{r, RoFp, echo=FALSE, fig.cap="Rate of Forgetting by Participant"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=MeanAlpha, text=paste0(userId))) +
  geom_boxplot(size=0.3) +
  geom_line(aes(group=userId), size=0.2, position=position_dodge(0)) +
  geom_point(aes(fill=userId, group=paired), size=3, shape=20, stroke=0, position=position_dodge(0)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Mean Rate of forgetting") +
  ggtitle("Rate of Forgetting by Participant") +
  labs(fill="Participant") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```

```{r, RoFC, echo=FALSE, fig.cap="Rate of Forgetting by Clinical Status"}

# Rate of Forgetting by Clinical Status
graph.clinical=ggplot(clinical, aes(x=level_order, y=MeanAlpha,col=clinicalStatus, fill=clinicalStatus,text=paste0(userId))) +
  geom_boxplot(size=0.3, alpha=0.2) +
  geom_line(aes(group=paired), size=0.2, position=position_dodge(0)) +
  geom_point(aes(fill=clinicalStatus, group=paired), size=3, shape=20, stroke=0, position=position_dodge(0)) +
  scale_color_manual(values = c("gold3", "purple3")) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Mean Rate of Forgetting") +
  ggtitle("Rate of Forgetting by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```
Individuals with MCI tend to have a higher Rate of Forgetting than the age-matched controls (fig \@ref(fig:RoFC)).

```{r, RoFAS, echo=FALSE, fig.cap="Rate of Forgetting by Clinical Status AS"}

PRoF1=ggplot(clinical, aes(y = MeanAlpha, x = level_order, col = clinicalStatus, fill = clinicalStatus)) +
  geom_boxplot(alpha=0.25) +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="point", fun.data="mean_sdl", size=3) +
  #stat_summary(geom="ribbon", fun.dat="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Mean Alpha") +
  ggtitle("Rate of Forgetting By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "none",
        axis.title.x = element_blank()) 

PRoF2=ggplot(clinical, aes(y=MeanAlpha, x =level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_boxplot() +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="point", fun.data="mean_sdl", size=3) +
  stat_summary(geom="ribbon", fun.dat ="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Mean Alpha") +
  ylim(0.3,0.5) +
  #ggtitle("Rate of Forgetting By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 


plot_grid(PRoF1, PRoF2, ncol = 1, nrow = 2)
  
```

```{r, RoFANOVA,echo=FALSE}
RoFANOVA <- aov(MeanAlpha ~ (lessonTitle * clinicalStatus) + Error(userId/lessonTitle),
          clinical) 

RoFANOVA %>%
  tidy() %>%
  xtable() %>%
  kbl(caption= "ANOVA using mean ROF as dependent variable and Clinical Status and Lesson as factors", digits = 4) %>%
  kable_paper(full_width = F) 
```

### Median Rate of Forgetting 

The median Rate of Forgetting for each participant across all lessons.

```{r, MedRoFAS, echo=FALSE, fig.cap="Median Rate of Forgetting by Clinical Status AS"}

PRoF3=ggplot(clinical, aes(y = MedianAlpha, x = level_order, col = clinicalStatus, fill = clinicalStatus)) +
  geom_boxplot(alpha=0.25) +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="point", fun.data="mean_sdl", size=3) +
  #stat_summary(geom="ribbon", fun.dat="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Median Alpha") +
  ggtitle("Rate of Forgetting By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "none",
        axis.title.x = element_blank()) 

PRoF4=ggplot(clinical, aes(y=MedianAlpha, x =level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_boxplot() +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="point", fun.data="mean_sdl", size=3) +
  stat_summary(geom="ribbon", fun.dat ="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("Median Alpha") +
  ylim(0.3,0.5) +
  #ggtitle("Rate of Forgetting By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 


plot_grid(PRoF3, PRoF4, ncol = 1, nrow = 2)
  
```

```{r, RoFANOVAmed,echo=FALSE}
RoFANOVAmed <- aov(MedianAlpha ~ (lessonTitle * clinicalStatus) + Error(userId/lessonTitle),
          clinical) 

RoFANOVAmed %>%
  tidy() %>%
  xtable() %>%
  kbl(caption= "ANOVA using median ROF as dependent variable and Clinical Status and Lesson as factors", digits = 4) %>%
  kable_paper(full_width = F) 
```

## Distribution of Rate of Forgetting

```{r, DisRoF, echo=FALSE, fig.cap="Distribution of Rate of Forgetting by Clinical Status"}

clinical_avg <- clinical %>% 
  group_by(userId, clinicalStatus) %>%
  summarise(RoF = mean(MeanAlpha))

PRoFD1 <- ggplot(clinical, aes(x=MeanAlpha, fill=clinicalStatus)) +
  geom_density(alpha=0.25, col="white", bw=0.02) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Mean Rate of Forgetting") +
  ggtitle("RoF Distributions\n(single sessions)") +
  ylab("Number of Observations") +
  xlim(c(0.2, 0.6)) +
  labs(fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom") 


PRoFD2 <- ggplot(clinical_avg, aes(x=RoF, fill=clinicalStatus)) +
  geom_density(alpha=0.25, col="white", bw=0.03) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Mean Rate of Forgetting") +
  ggtitle("RoF Distributions\n(averaged)") +
  ylab("Number of Observations") +
  xlim(c(0.2, 0.6)) +
  labs(fill="Clinical Status") +
  theme_pander() +
  theme(legend.position = "bottom") 


## This is a function from the 'cowplot' package
plot_grid(PRoFD1, PRoFD2, labels=c("A", "B"), ncol = 2, nrow = 1)

```

This figure examines the distribution of ROF values for MCIs and controls, either across all sessions (A) or averaged across all sessions (B) (fig \@ref(fig:DisRoF)). The biggest point of difference, whether single session or averaged sessions, is at an alpha of about 0.37. The double bump in Figure \ref{fig:DisRoF}A is likely due to differences in task difficulty. An interesting point here is that there are some things that are easier for the the MCI than for the controls (shown by that middle section overlap) and this makes it harder for the classifier. If we could build a classifier that has a general idea of difficulty (for instance, have the threshold for “birds”-which is an easier task- be 0.35 instead of 0.37), it would be much better.  

## Classification accuracy

One of the most interesting questions which is, “How diagnostic is the Rate of Forgetting?”  To analyze a parameter's classification accuracy, you can plot an ROC curve. This curve will assess the sensitivity and specificity- two components that measure the inherent validity of a diagnostic test- of ROF as a diagnostic tool. First, we examined the ROC curve for just a single 8 minute session of data.    

```{r, results= 'hide', echo=FALSE}

# Single Session

curve <- NULL
mlclinical <- clinical %>%
  #group_by(userId,clinicalStatus) %>%
  #summarize(MeanAlpha=mean(MeanAlpha), MedianAlpha = median(MeanAlpha)) %>%
  mutate(observed = ifelse(clinicalStatus == "MCI", -1, 1)) 

for (threshold in seq(0.2, 0.8, 0.01)) {
  subthreshold <- mlclinical %>%
    mutate(prediction = ifelse(MeanAlpha <= threshold, 1, -1)) %>%
    mutate(accuracy = ifelse(prediction == observed, 1, 0)) %>%
    group_by(observed) %>%
    summarise(accuracy = mean(accuracy))
  
  tnr <- subthreshold %>% 
    filter(observed == -1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  tpr <- subthreshold %>% 
    filter(observed == 1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  partial <- tibble(Threshold = threshold,
                    TNR = tnr,
                    TPR = tpr)
  if (is.null(curve)) {
    curve <- partial
  } else {
    curve <- rbind(curve, partial)
  }
}

AUC <- 0
step <- 0.01
for (tnr in seq(0, 1, step)) {
  y <- curve %>% filter (TNR <= tnr) %>% filter(TNR == max(TNR)) %>% summarise(TPR = mean(TPR)) %>% as.numeric()
  AUC <- AUC + (y * step)
}

```

```{r, Class, echo=FALSE, fig.cap="Classification Accuracy for different RoF thresholds"}
curve <- curve %>% mutate(auc = (TPR + TNR)/2)

ggplot(arrange(curve, TPR), aes(x=TNR, y=TPR)) + 
  geom_point(size=2, col="purple", alpha=0.5) + 
  geom_line(col="purple") + 
  geom_text_repel(aes(label=paste("RoF =", Threshold, "\n AUC =", percent(auc, .2))), 
                  col="black",
                  #position=position_stack(vjust=0.5), 
                  direction="both",
                  size=3) +
  ylab("Sensitivity (True Positive Rate)") +
  xlab("Specificity (True Negative Rate)") +
  scale_x_reverse() +
  ylim(0, 1) +
  xlim(1, 0) +
  coord_equal() +
  ggtitle("ROC Curve for Different Thresholds (Single)") +
  geom_abline(slope=1, intercept = 1, col="grey", linetype = "dashed") +
  theme_pander()
```

This figure visualizes the ROC curve to see the classification accuracy at each RoF threshold (fig \@ref(fig:Class)). In this case, having a RoF value of 0.37 as the diagnostic threshold- that is people with an RoF of 0.37 and up are considered mildly cognitively impaired and people with an RoF less than are healthy controls- gives us a diagnostic classification accuracy of 76%. All together though, the global AUC for single session is `r AUC`.  

```{r, results='hide', echo=FALSE}

# Average of all sessions

curve <- NULL
mlclinical <- clinical %>%
  group_by(userId,clinicalStatus) %>%
  summarize(MeanAlpha=mean(MeanAlpha), MedianAlpha = median(MeanAlpha)) %>%
  mutate(observed = ifelse(clinicalStatus == "MCI", -1, 1)) 

for (threshold in seq(0.2, 0.8, 0.01)) {
  subthreshold <- mlclinical %>%
    mutate(prediction = ifelse(MeanAlpha <= threshold, 1, -1)) %>%
    mutate(accuracy = ifelse(prediction == observed, 1, 0)) %>%
    group_by(observed) %>%
    summarise(accuracy = mean(accuracy))
  
  tnr <- subthreshold %>% 
    filter(observed == -1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  tpr <- subthreshold %>% 
    filter(observed == 1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  partial <- tibble(Threshold = threshold,
                    TNR = tnr,
                    TPR = tpr)
  if (is.null(curve)) {
    curve <- partial
  } else {
    curve <- rbind(curve, partial)
  }
}

AVGAUC <- 0
step <- 0.01
for (tnr in seq(0, 1, step)) {
  y <- curve %>% filter (TNR <= tnr) %>% filter(TNR == max(TNR)) %>% summarise(TPR = mean(TPR)) %>% as.numeric()
  AVGAUC <- AVGAUC + (y * step)
}
```


```{r, Classavg, echo=FALSE, fig.cap="Classification Accuracy for different averaged RoF thresholds"}
curve <- curve %>% mutate(auc = (TPR + TNR)/2)

ggplot(arrange(curve, TPR), aes(x=TNR, y=TPR)) + 
  geom_point(size=2, col="purple", alpha=0.5) + 
  geom_line(col="purple") + 
  geom_text_repel(aes(label=paste("RoF =", Threshold, "\n AUC =", percent(auc, .2))), 
                  col="black",
                  #position=position_stack(vjust=0.5), 
                  direction="both",
                  size=3) +
  ylab("Sensitivity (True Positive Rate)") +
  xlab("Specificity (True Negative Rate)") +
  scale_x_reverse() +
  ylim(0, 1) +
  xlim(1, 0) +
  coord_equal() +
  ggtitle("ROC Curve for Different Thresholds (AVG)") +
  geom_abline(slope=1, intercept = 1, col="grey", linetype = "dashed") +
  theme_pander()
```

This figure visualizes the ROC curve to see the classification accuracy at each RoF threshold (fig \@ref(fig:Classavg)). The global AUC for averaged sessions is `r AVGAUC`.

