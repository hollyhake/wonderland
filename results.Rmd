---
output:
  pdf_document: default
  html_document: default
---
# Results

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(broom)
library(reshape2)
library(glmnet)
library(readr)

# Graphics
library(ggplot2)
library(ggthemes)
library(ggrepel)
library(ppcor)
library(ggExtra)
library(ggsci)
library(viridis)
library(scales)
library(patchwork)# Multi-plot alignment
library(ggcorrplot)
library(gapminder) # dataset used to make the box plot connected by lines
library(RColorBrewer) 
library(plotly) # Added to make interactive graphs 
library(lubridate) # Added to make interactive graphs; use different date funcs
library(stringr) # Added to make interactive graphs; use different txt funcs
library(extrafont) # Added to make interactive graphs; change font on graphs
library(htmlwidgets) # Added to make interactive graphs; make exports interactive
library(cowplot)

# Tables
library(kableExtra)
library(xtable)
library(reactable) # Added to make pretty tables
library(htmltools) # Added to make pretty tables

# Date functions
library(anytime)
library(lubridate)

# SlimStampen

#install.packages("devtools") # Install SlimStampen packages. Instructions on https://github.com/VanRijnLab/SlimStampeRData
library(devtools)
#devtools::install_github("VanRijnLab/SlimStampeRData",
                      #   build_vignettes = TRUE,
                       #  dependencies = TRUE,
                        # force = TRUE) 
# The console will show a prompt asking whether all packages should be updated. Select option 1 (by typing 1 and then pressing enter), this will update all packages.
vignette("SlimStampeRVignette")
library(SlimStampeRData)

```


```{r, echo=FALSE, results= 'hide'}

# Load data
load("C:/Users/17203/Documents/GitHub/Blaarkop/data/SlimStampen_2022-09-09.RData")

# Filter for just ADRC subjects & group by clinical status
groups <- read_csv("C:/Users/17203/Documents/GitHub/Blaarkop/groups.csv", show_col_types = FALSE)
data %>% 
  filter(userId %in% groups$userId) -> data

# Filter bad trials (as reported by subjects)
data$userId <- as.character(data$userId)
data <- data[!(data$userId=="69425" & lessonTitle=="Art"),]
data$userId <- as.numeric(data$userId)


# Filter for reaction times higher than 50 seconds
#data %>% 
 # group_by(userId, sessionId, lessonId, lessonTitle, reactionTime) %>% 
 # mutate(reactionlegit =if_else(reactionTime <50000, T, F)) %>%
 # filter(reactionlegit == T) %>%
 # ungroup() -> data

```


```{r, echo=FALSE, results= 'hide'}

# Calculate fact rep, activation, and alpha 
MAX_ALPHA=0.8
data <- data %>%
  calculate_repetition() %>%
  calculate_alpha_and_activation(maxAlpha=MAX_ALPHA)

```
```{r, echo=FALSE, results= 'hide'}


options(dplyr.summarise.inform = FALSE) # Disable the "`summarise()` has grouped output by" message 

# Calculate avg alpha
data_lastRep <- data %>%
  group_by(lessonId, userId, sessionId, factId) %>%
  mutate(LastRepetition = max(repetition)) %>%
  filter(repetition == LastRepetition) %>%
  ungroup()

data_avg1 <- data_lastRep %>%
  group_by(userId, lessonTitle, lessonId, sessionId) %>%
  summarise(MeanAlpha = mean(alpha), MedianAlpha = median(alpha)) 

data_avg2 <- data %>%
  group_by(lessonId, userId, sessionId) %>%
  summarise(correct = mean(correct), responseTime=mean(reactionTime)) %>%
  ungroup()

data_avg <- data_avg1 %>% inner_join(data_avg2)

data_avg %>% 
  group_by(userId, lessonTitle, lessonId) %>% 
  summarize(numSess=length(unique(sessionId))) 


# Filter the sessions
sessionData <- data %>% 
  group_by(userId, sessionId, lessonId, lessonTitle) %>% 
  summarize(duration = (max(presentationStartTime) - min(presentationStartTime))/60000,
            start = min(presentationStartTime),
            legit = if_else(duration > 6, T, F)) 

sessionData <- sessionData %>% 
  group_by(userId, lessonId, lessonTitle) %>% 
  arrange(start, by_group=T) %>%
  mutate(sessionRank = seq(1, length(start)))

sessionDataFiltered <- sessionData %>%
  filter(legit == T) %>%
  group_by(userId, lessonId) %>%
  mutate(minRank = min(sessionRank))

sessionData <- sessionData %>%
  inner_join(sessionDataFiltered) %>%
  mutate(usable = if_else(minRank == sessionRank, T, F))

# Group by Clinical Status
data <- inner_join(data, groups)

# Clean the filtered data set
cleandata <- inner_join(sessionData, data) %>%
  filter(usable == T)
cleandata$userId <- as.character(cleandata$userId)
cleandata$level_order<- factor(cleandata$lessonTitle, level = c('Pasta','Swahili 1','Flowers','European Capitals 1','Birds', 'Newspapers','Asian Flags', 'Folktales', 'Maps', 'US Towns 1', 'Art', 'Hindu Gods','Cheese')) # order by lessons


# Group by clinical status
clinical <- inner_join(data_avg, groups) %>%
  inner_join(sessionData) %>%
  filter(usable == T)


# Change 'userId' from numeric to character
clinical$userId <- as.character(clinical$userId)
clinical <- clinical %>%
  mutate(paired= factor(userId))

# Change responseTime from ms to s
clinical$responseTime <- (clinical$responseTime/1000)

# Delete practice
clinical <- clinical[!(clinical$lessonTitle=="01 Practice"), ]

# **Testing taking out outlier participant lessons
#clinical <- clinical[-c(67,70,72,73,87), ] 
#clinical <- clinical[!(clinical$userId=="69415"), ]

#data$userId <- as.character(data$userId)
#data <- data[!(data$userId=="69425"),(data$lessonTitle=="Art") ]


# Order the lessons by week
clinical$level_order<- factor(clinical$lessonTitle, level = c('Pasta','Swahili 1','Flowers','European Capitals 1','Birds', 'Newspapers','Asian Flags', 'Folktales', 'Maps', 'US Towns 1', 'Art', 'Hindu Gods','Cheese'))

xlabels <- c("Pasta", "Swahili", "Flowers", "Capitals", "Birds","News", "Flags", "Folktales", "Maps", "Towns", "Art", "Hindi","Cheese")

# Order the users by time they joined the study
clinical$user_order<- factor(clinical$userId, level = c('69410','69411','69412','69414','69415','69417','69418','69419','69427','70930','69421','69422','69423','69425','70925', '71203'))

```


## Data Tables


```{r, echo=FALSE}
clinical %>% 
  group_by(level_order, clinicalStatus) %>% 
  summarise(n=length(userId)) %>%
  pivot_wider(names_from=clinicalStatus, values_from = n) %>%
  rowwise() %>% 
  mutate(sumVar = sum(c_across(Control:MCI))) %>%
  kbl(caption= "Number of Control and MCI participants that completed each lesson", col.names = c("Lesson", "Control", "MCI", "Total")) %>%
  kable_styling() %>%
  column_spec(3,color = "purple") %>%
  column_spec(4,bold= T,border_left = T) %>%
  column_spec(1, image = spec_image(c(
    "C:/Users/17203/Documents/wonderland/images/pasta.png",
    "C:/Users/17203/Documents/wonderland/images/swahili.png", 
    "C:/Users/17203/Documents/wonderland/images/flowers.png", 
    "C:/Users/17203/Documents/wonderland/images/eurocaps.png", 
    "C:/Users/17203/Documents/wonderland/images/birds.png",
    "C:/Users/17203/Documents/wonderland/images/news.png",
    "C:/Users/17203/Documents/wonderland/images/asianflags.png",
    "C:/Users/17203/Documents/wonderland/images/folktales.png",
    "C:/Users/17203/Documents/wonderland/images/maps.png",
    "C:/Users/17203/Documents/wonderland/images/ustowns1.png", 
    "C:/Users/17203/Documents/wonderland/images/art.png",
    "C:/Users/17203/Documents/wonderland/images/hindi.png",
    "C:/Users/17203/Documents/wonderland/images/cheese.png"
    ), 50, 50)) %>% # Add images to the table 
  kable_paper(full_width = T) 

```

```{r fact, echo=FALSE, fig.cap="Number of facts seen in each lesson"}
cd1 <-   cleandata %>% 
  group_by(userId, clinicalStatus, level_order, factAnswer) %>% 
   summarize(numfacts=length(unique(factAnswer))) 

cd2 <- cd1 %>% 
  group_by(userId) %>% 
  summarize(numlessons=length(unique(level_order))) %>%
  ungroup()

cd3 <- cd1 %>%
  inner_join(cd2)


options(digits=3) 

cd3 %>%
  group_by(userId, clinicalStatus, numlessons, level_order, factAnswer) %>% 
  pivot_wider(names_from=factAnswer, values_from = numfacts)%>%
  replace(is.na(.), 0) %>%
  mutate(sumfacts = sum(c_across(where(is.numeric))), .after = clinicalStatus) %>%
  summarize(Avg=(sumfacts))  %>%
  pivot_wider(names_from=level_order, values_from = Avg) %>%
  replace(is.na(.), 0) %>%
  mutate(Avg = ((sum(across(where(is.numeric))))/(numlessons)), .after = numlessons) %>%
  arrange(clinicalStatus, desc(Avg)) %>%
  #adorn_totals( where = "row", fill = "-", na.rm = TRUE, name = "Total")%>%
  kbl(caption= "Number of facts seen in each lesson", col.names = c("Participant", "Group", "Lessons", "AVG", "Pasta", "Swahili", "Flowers", "Capitals", "Birds","News", "Flags", "Folktales", "Maps", "Towns", "Art", "Hindi","Cheese")) %>%
  kable_styling() %>%
  #row_spec(which(cd3$Pasta >6),background=ifelse"#f3e8ff") %>%
  #column_spec(3, background=ifelse(cd3$numlessons >3, "#f3e8ff")) %>%
  column_spec(4,bold= T,border_right = T) %>%
  column_spec(3,color="green") %>%
  #column_spec(4,) %>%
 kable_paper(full_width = F) 

```



## Accuracy 

```{r, Acc, echo=FALSE, fig.cap="Accuracy Across Lessons"}

PAcc1=ggplot(clinical, aes(x=level_order, y=correct, col=lessonTitle, fill=lessonTitle)) +
  #geom_violin(width=1, alpha=0.2) +
  geom_boxplot(width=.5, alpha=0.2) +
  #stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape= 1, color="black") +
  geom_point(size=2, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("accuracy") +
  ggtitle("Accuracy Across Lessons") +
  theme_hc() +
  theme(legend.position = "none",
        axis.title.x=element_blank())

PAcc2=ggplot(clinical, aes(y = correct, x = level_order, col = clinicalStatus, fill = clinicalStatus)) +
  #geom_violin(alpha=0.2) +
  geom_boxplot(alpha=0.25) +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  geom_point(size=2, position=position_jitter(0.1)) +
  #stat_summary(geom="ribbon", fun.dat="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  #stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("accuracy") +
  ggtitle(" ") +
 # ggtitle("Accuracy Across Lessons By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_hc() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 



plot_grid(PAcc1, PAcc2, ncol = 1, nrow = 2)

```


Accuracy (fig \@ref(fig:Acc)) scores were averaged for each participant in each lesson they completed. 

```{r, Accp, echo=FALSE, fig.cap="Accuracy by Participant"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=correct, text=paste0(userId))) +
  geom_boxplot(size=0.1) +
  geom_line(aes(group=userId, col=userId), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=userId, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean accuracy") +
  ggtitle("Accuracy by Participant") +
  labs(fill="Participant", col="Participant") +
  theme_hc() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```

This graph is interactive (fig \@ref(fig:Accp)). Hover over the data points to get a better look at the accuracy scores for each participant. Double click on a participant ID to isolate that participant's data points. 



```{r, AccC, echo=FALSE, fig.cap="Accuracy by Clinical Status"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=correct, col=clinicalStatus, fill=clinicalStatus, text=paste0(userId)))+
  geom_boxplot(size =0.1, alpha=0.2) +
  geom_line(aes(group=paired), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=clinicalStatus, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  scale_color_manual(values = c("gold3", "purple3")) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean accuracy") +
  ggtitle("Accuracy by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_hc() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```

This graph separates the participants by clinical status (fig \@ref(fig:AccC)). Participants with MCI tend to have less accuracy compared to the controls.  

## Response Time

```{r, RT, echo=FALSE, fig.cap="Response Time Across Lessons"}

PRT1=ggplot(clinical, aes(x=level_order, y=responseTime, col=lessonTitle, fill=lessonTitle)) +
  #geom_violin(width=1, alpha=0.2) +
  geom_boxplot(width=.5, alpha=0.2) +
  #stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape= 1, color="black") +
  geom_point(size=2, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("sec") +
  ggtitle("Response Time Across Lessons") +
  theme_hc() +
  theme(legend.position = "none",
        axis.title.x=element_blank())

PRT2=ggplot(clinical, aes(y=responseTime, x=level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_violin(alpha=0.2) +
  geom_boxplot(alpha=0.25) +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  geom_point(size=2, position=position_jitter(0.1)) +
  #stat_summary(geom="ribbon", fun.dat="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  #stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("sec") +
  ggtitle(" ") +
 # ggtitle("Response Time Across Lessons by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_hc() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 



plot_grid(PRT1, PRT2, ncol = 1, nrow = 2)

```

Response times (fig \@ref(fig:RT)) were averaged for each participant in each lesson they completed. 


```{r, RTp, echo=FALSE, fig.cap="Response Time by Participant"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=responseTime, text=paste0(userId))) +
  geom_boxplot(size=0.1) +
  geom_line(aes(group=userId, col=userId), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=userId, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("sec") +
  ggtitle("Response Time by Participant") +
  labs(fill="Participant", col="Participant") +
  theme_hc() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)


cleandata <- inner_join(sessionData, data) %>%
  filter(usable == T)

cleandata$userId <- as.character(cleandata$userId)

# Change reactionTime from ms to s
cleandata$reactionTime <- (cleandata$reactionTime/1000)


graph=ggplot(cleandata, aes(x=factAnswer, y=reactionTime, col=userId, text=paste0(userId)))+
  geom_point(size=0.5, position=position_jitter(0.1)) +
       xlab("Fact") +
  ylab("sec") +
  ggtitle("Response Time for Each Fact") +
  labs(fill="Participant", col="Participant") +
  theme_hc() +
  theme(#legend.position = "none",
        axis.text.x = element_text (angle=90, size=3))
ggplotly(graph, tooltip=c("y", "text")) %>% 
  config(displayModeBar=FALSE)

```
The graph is interactive (fig \@ref(fig:RTp)). Hover over the data points to get a better look at the response times for each participant. Double click on a participant ID to isolate that participant's data points. 

```{r, RTc, echo=FALSE, fig.cap="Response Time by Clinical Status"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=responseTime, col=clinicalStatus, fill=clinicalStatus, text=paste0(userId)))+
  geom_boxplot(size =0.1, alpha=0.2) +
  geom_line(aes(group=paired), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=clinicalStatus, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  scale_color_manual(values = c("gold3", "purple3")) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("sec") +
  ggtitle("Response Time by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_hc() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```


## Rate of Forgetting 

The mean Rate of Forgetting for each participant across all lessons. 

```{r, RoF, echo=FALSE, fig.cap="Rate of Forgetting Across Lessons"}

ggplot(clinical, aes(x=level_order, y=MeanAlpha, col=lessonTitle, fill=lessonTitle)) +
  geom_violin(width=1, size=0.1, alpha=0.2) +
  #geom_boxplot(width=.4,size=0.1, alpha=0.2) +
  stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape=1, color="black") +
  geom_point(size=3, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean alpha") +
  ggtitle("Rate of Forgetting Across Lessons") +
  theme_hc() +
  theme(legend.position="none")


```
```{r, RoF1, echo=FALSE, fig.cap="Rate of Forgetting Across Lessons"}

PRoF1=ggplot(clinical, aes(x=level_order, y=MeanAlpha, col=lessonTitle, fill=lessonTitle)) +
  #geom_violin(width=1, alpha=0.2) +
  geom_boxplot(width=.5, alpha=0.2) +
  #stat_summary(fun.y=mean, geom="pointrange", size=0.3, shape= 1, color="black") +
  geom_point(size=2, position=position_jitter(0.1)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("alpha") +
  ggtitle("Rate of Forgetting Across Lessons") +
  theme_hc() +
  theme(legend.position = "none",
        axis.title.x=element_blank())

PRoF2=ggplot(clinical, aes(y=MeanAlpha, x=level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_violin(alpha=0.2) +
  geom_boxplot(alpha=0.25) +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  geom_point(size=2, position=position_jitter(0.1)) +
  #stat_summary(geom="ribbon", fun.dat="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  #stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("alpha") +
  ggtitle(" ") +
 # ggtitle("Rate of Forgetting Across Lessons by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_hc() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 



plot_grid(PRoF1, PRoF2, ncol = 1, nrow = 2)

```
Rates of Forgetting 'alpha' (fig \@ref(fig:RoF1)) were averaged for each participant in each lesson they completed. 


```{r, RoFp, echo=FALSE, fig.cap="Rate of Forgetting by Participant"}

graph.clinical=ggplot(clinical, aes(x=level_order, y=MeanAlpha, text=paste0(userId))) +
  geom_boxplot(size=0.1) +
  geom_line(aes(group=userId, col=userId), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=userId, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean alpha") +
  ggtitle("Rate of Forgetting by Participant") +
  labs(fill="Participant", col="Participant") +
  theme_hc() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```

```{r, RoFC, echo=FALSE, fig.cap="Rate of Forgetting by Clinical Status"}

# Rate of Forgetting by Clinical Status
graph.clinical=ggplot(clinical, aes(x=level_order, y=MeanAlpha,col=clinicalStatus, fill=clinicalStatus,text=paste0(userId))) +
  geom_boxplot(size=0.1, alpha=0.2) +
  geom_line(aes(group=paired), size=0.1, position=position_dodge(0)) +
  geom_point(aes(fill=clinicalStatus, group=paired), size=2, shape=20, stroke=0, position=position_dodge(0)) +
  scale_color_manual(values = c("gold3", "purple3")) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean alpha") +
  ggtitle("Rate of Forgetting by Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_hc() +
  theme(axis.title.x=element_blank(),
        panel.grid.major = element_blank())

ggplotly(graph.clinical, tooltip=c("y", "text")) %>% 
  layout(legend = list(orientation = "h")) %>% 
  config(displayModeBar=FALSE)

```
Individuals with MCI tend to have a higher Rate of Forgetting than the age-matched controls (fig \@ref(fig:RoFC)).

```{r, mmRoF, echo=FALSE, fig.cap="Mean and Median Rate of Forgetting by Clinical Status"}

PRoFmean=ggplot(clinical, aes(y=MeanAlpha, x =level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_boxplot() +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="point", fun.data="mean_sdl", size=3) +
  stat_summary(geom="ribbon", fun.dat ="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("mean alpha") +
  ggtitle("Rate of Forgetting By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_hc() +
  theme(legend.position = "none",
        axis.title.x = element_blank()) 

PRoFmed=ggplot(clinical, aes(y=MedianAlpha, x =level_order, col=clinicalStatus, fill=clinicalStatus)) +
  #geom_boxplot() +
  #stat_summary(geom="errorbar", fun.data = "mean_se", width=0.1) +
  stat_summary(geom="point", fun.data="mean_sdl", size=3) +
  stat_summary(geom="ribbon", fun.dat ="mean_se", aes(group=clinicalStatus), col=NA, alpha=0.25) +
  stat_summary(geom="line", fun="mean", aes(group=clinicalStatus)) +
  scale_color_manual(values=c("gold3", "purple3")) +
  scale_fill_manual(values=c("gold3", "purple3")) +
  xlab("Lesson") +
  scale_x_discrete(labels=xlabels) +
  ylab("median alpha") +
  #ggtitle("Rate of Forgetting By Clinical Status") +
  labs(col="Clinical Status", fill="Clinical Status") +
  theme_hc() +
  theme(legend.position = "bottom",
        axis.title.x = element_blank()) 


plot_grid(PRoFmean, PRoFmed, ncol = 1, nrow = 2)
  
```

```{r, RoFANOVA,echo=FALSE}
RoFANOVA <- aov(MeanAlpha ~ (lessonTitle * clinicalStatus) + Error(userId/lessonTitle),
          clinical) 

RoFANOVA %>%
  tidy() %>%
  xtable() %>%
  kbl(caption= "ANOVA using mean ROF as dependent variable and Clinical Status and Lesson as factors", digits = 4) %>%
  kable_paper(full_width = F) 

```

The median Rate of Forgetting for each participant across all lessons.


```{r, RoFANOVAmed,echo=FALSE}
RoFANOVAmed <- aov(MedianAlpha ~ (lessonTitle * clinicalStatus) + Error(userId/lessonTitle),
          clinical) 

RoFANOVAmed %>%
  tidy() %>%
  xtable() %>%
  kbl(caption= "ANOVA using median ROF as dependent variable and Clinical Status and Lesson as factors", digits = 4) %>%
  kable_paper(full_width = F) 
```

## Distribution of Rate of Forgetting

```{r, DisRoF, echo=FALSE, fig.cap="Distribution of Rate of Forgetting by Clinical Status"}

clinical_avg <- clinical %>% 
  group_by(userId, clinicalStatus) %>%
  summarise(RoF = mean(MeanAlpha))

PRoFD1 <- ggplot(clinical, aes(x=MeanAlpha, fill=clinicalStatus)) +
  geom_density(alpha=0.25, col="white", bw=0.02) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Mean Rate of Forgetting") +
  ggtitle("RoF Distributions\n(single sessions)") +
  ylab("Number of Observations") +
  xlim(c(0.2, 0.6)) +
  labs(fill="Clinical Status") +
  theme_hc() +
  theme(legend.position = "bottom") 


PRoFD2 <- ggplot(clinical_avg, aes(x=RoF, fill=clinicalStatus)) +
  geom_density(alpha=0.25, col="white", bw=0.03) +
  scale_fill_manual(values = c("gold3", "purple3")) +
  xlab("Mean Rate of Forgetting") +
  ggtitle("RoF Distributions\n(averaged)") +
  ylab("Number of Observations") +
  xlim(c(0.2, 0.6)) +
  labs(fill="Clinical Status") +
  theme_hc() +
  theme(legend.position = "bottom") 


## This is a function from the 'cowplot' package
plot_grid(PRoFD1, PRoFD2, labels=c("A", "B"), ncol = 2, nrow = 1)

```

This figure examines the distribution of ROF values for MCIs and controls, either across all sessions (A) or averaged across all sessions (B) (fig \@ref(fig:DisRoF)). The biggest point of difference, whether single session or averaged sessions, is at an alpha of about #. The double bump in Figure \ref{fig:DisRoF}A is likely due to differences in task difficulty. An interesting point here is that there are some things that are easier for the the MCI than for the controls (shown by that middle section overlap) and this makes it harder for the classifier. If we could build a classifier that has a general idea of difficulty (for instance, have the threshold for “birds”-which is an easier task- be 0.35 instead of 0.37), it would be much better.  

## Classification accuracy

One of the most interesting questions which is, “How diagnostic is the Rate of Forgetting?”  To analyze a parameter's classification accuracy, you can plot an ROC curve. This curve will assess the sensitivity and specificity- two components that measure the inherent validity of a diagnostic test- of ROF as a diagnostic tool. First, we examined the ROC curve for just a single 8 minute session of data.    

```{r, results= 'hide', echo=FALSE}

# Single Session

curve <- NULL
mlclinical <- clinical %>%
  #group_by(userId,clinicalStatus) %>%
  #summarize(MeanAlpha=mean(MeanAlpha), MedianAlpha = median(MeanAlpha)) %>%
  mutate(observed = ifelse(clinicalStatus == "MCI", -1, 1)) 

for (threshold in seq(0.2, 0.8, 0.01)) {
  subthreshold <- mlclinical %>%
    mutate(prediction = ifelse(MeanAlpha <= threshold, 1, -1)) %>%
    mutate(accuracy = ifelse(prediction == observed, 1, 0)) %>%
    group_by(observed) %>%
    summarise(accuracy = mean(accuracy))
  
  tnr <- subthreshold %>% 
    filter(observed == -1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  tpr <- subthreshold %>% 
    filter(observed == 1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  partial <- tibble(Threshold = threshold,
                    TNR = tnr,
                    TPR = tpr)
  if (is.null(curve)) {
    curve <- partial
  } else {
    curve <- rbind(curve, partial)
  }
}

AUC <- 0
step <- 0.01
for (tnr in seq(0, 1, step)) {
  y <- curve %>% filter (TNR <= tnr) %>% filter(TNR == max(TNR)) %>% summarise(TPR = mean(TPR)) %>% as.numeric()
  AUC <- AUC + (y * step)
}

```

```{r, Class, echo=FALSE, fig.cap="Classification Accuracy for different RoF thresholds"}
curve <- curve %>% mutate(auc = (TPR + TNR)/2)

ggplot(arrange(curve, TPR), aes(x=TNR, y=TPR)) + 
  geom_point(size=2, col="purple", alpha=0.5) + 
  geom_line(col="purple") + 
  geom_text_repel(aes(label=paste("RoF =", Threshold, "\n AUC =", percent(auc, .2))), 
                  col="black",
                  #position=position_stack(vjust=0.5), 
                  direction="both",
                  size=3) +
  ylab("Sensitivity (True Positive Rate)") +
  xlab("Specificity (True Negative Rate)") +
  scale_x_reverse() +
  ylim(0, 1) +
  xlim(1, 0) +
  coord_equal() +
  ggtitle("ROC Curve for Different Thresholds (Single)") +
  geom_abline(slope=1, intercept = 1, col="grey", linetype = "dashed") +
  theme_hc()
```

This figure visualizes the ROC curve to see the classification accuracy at each RoF threshold (fig \@ref(fig:Class)). In this case, having a RoF value of 0.# as the diagnostic threshold- that is people with an RoF of 0.# and up are considered mildly cognitively impaired and people with an RoF less than are healthy controls- gives us a diagnostic classification accuracy of #%. All together though, the global AUC for single session is `r AUC`.  

```{r, results='hide', echo=FALSE}

# Average of all sessions

curve <- NULL
mlclinical <- clinical %>%
  group_by(userId,clinicalStatus) %>%
  summarize(MeanAlpha=mean(MeanAlpha), MedianAlpha = median(MeanAlpha)) %>%
  mutate(observed = ifelse(clinicalStatus == "MCI", -1, 1)) 

for (threshold in seq(0.2, 0.8, 0.01)) {
  subthreshold <- mlclinical %>%
    mutate(prediction = ifelse(MeanAlpha <= threshold, 1, -1)) %>%
    mutate(accuracy = ifelse(prediction == observed, 1, 0)) %>%
    group_by(observed) %>%
    summarise(accuracy = mean(accuracy))
  
  tnr <- subthreshold %>% 
    filter(observed == -1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  tpr <- subthreshold %>% 
    filter(observed == 1) %>% 
    dplyr::select(accuracy) %>%
    as.numeric()
  
  partial <- tibble(Threshold = threshold,
                    TNR = tnr,
                    TPR = tpr)
  if (is.null(curve)) {
    curve <- partial
  } else {
    curve <- rbind(curve, partial)
  }
}

AVGAUC <- 0
step <- 0.01
for (tnr in seq(0, 1, step)) {
  y <- curve %>% filter (TNR <= tnr) %>% filter(TNR == max(TNR)) %>% summarise(TPR = mean(TPR)) %>% as.numeric()
  AVGAUC <- AVGAUC + (y * step)
}
```


```{r, Classavg, echo=FALSE, fig.cap="Classification Accuracy for different averaged RoF thresholds"}
curve <- curve %>% mutate(auc = (TPR + TNR)/2)

ggplot(arrange(curve, TPR), aes(x=TNR, y=TPR)) + 
  geom_point(size=2, col="purple", alpha=0.5) + 
  geom_line(col="purple") + 
  geom_text_repel(aes(label=paste("RoF =", Threshold, "\n AUC =", percent(auc, .2))), 
                  col="black",
                  #position=position_stack(vjust=0.5), 
                  direction="both",
                  size=3) +
  ylab("Sensitivity (True Positive Rate)") +
  xlab("Specificity (True Negative Rate)") +
  scale_x_reverse() +
  ylim(0, 1) +
  xlim(1, 0) +
  coord_equal() +
  ggtitle("ROC Curve for Different Thresholds (AVG)") +
  geom_abline(slope=1, intercept = 1, col="grey", linetype = "dashed") +
  theme_hc()
```

This figure visualizes the ROC curve to see the classification accuracy at each RoF threshold (fig \@ref(fig:Classavg)). The global AUC for averaged sessions is `r AVGAUC`.


## RoF Correlations 

```{r, results ='hide', echo=FALSE}

# create a matrix of Participant by Lesson RoFs:

clinical %>% 
  pivot_wider(id_cols = lessonId, 
              names_from = userId, 
              values_from = MeanAlpha, 
              names_prefix="sub") %>% 
  ungroup() %>% 
  select(-lessonId) %>% 
  as.matrix() %>% 
  t() %>%
  cor(use="complete.obs") -> C

# remove self-correlations
C_noself <- C
C_noself[C==1] <- NA

```

```{r Corr, echo=FALSE, fig.cap="RoF Test-Retest Reliability"}
clinical %>% 
#  filter(!userId %in% tooFew[[1]]) %>% 
  pivot_wider(id_cols = lessonTitle, 
              names_from = userId, 
              values_from = MeanAlpha, 
              names_prefix="sub") %>% 
  ungroup() %>% 
  select(lessonTitle) %>% 
  as.vector() %>% 
  c() -> L

L <- L[[1]]

D <- as.data.frame(C)
names(D) <- L
D$Lesson <- L

D <- as_tibble(D)


correlations <- D %>%
  pivot_longer(cols=-Lesson, names_to = "With", values_to = "r")

correlations$Lesson<- factor(correlations$Lesson, level = c('Pasta','Swahili 1','Flowers','European Capitals 1','Birds', 'Newspapers','Asian Flags', 'Folktales','Maps', 'US Towns 1', 'Art','Hindu Gods','Cheese'))
correlations$With<- factor(correlations$With, level = c('Pasta','Swahili 1','Flowers','European Capitals 1','Birds', 'Newspapers','Asian Flags', 'Folktales','Maps', 'US Towns 1', 'Art','Hindu Gods','Cheese'))

ggplot(correlations, aes(x=Lesson, y=With, fill=r)) +
  geom_tile(col="white", size=1) +
  scale_fill_viridis(option="inferno", limits=c(0, 1)) +
#  scale_fill_continuous(limits=c(0, 1)) +
  coord_equal() +
  ggtitle("RoF Correlations Across Lessons") +
  geom_text(aes(label=sprintf("%0.2f",
                              round(r, digits = 2))), 
            size=3) +
  theme(axis.text.x=element_text(angle=45, hjust = 1)) +
  theme_hc()
```

This figure visualizes the test-retest reliability of the RoF using correlations across materials  (fig \@ref(fig:Corr)). The mean correlation is `r round(mean(C_noself, na.rm=T), 3)`. 

